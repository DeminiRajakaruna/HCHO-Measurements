{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check location amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME\n",
      "COLOMBO, CE         1765\n",
      "NUWARA ELIYA, CE    1761\n",
      "CHINA BAY, CE       1760\n",
      "PUTTALAM, CE        1755\n",
      "KURUNEGALA, CE      1704\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('D:\\DESKTOP\\DE CW\\External_Data.csv')\n",
    "\n",
    "# Count the occurrences of each value in the \"NAME\" column\n",
    "name_counts = df['NAME'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(name_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " STATION         0\n",
      "NAME            0\n",
      "LATITUDE        0\n",
      "LONGITUDE       0\n",
      "ELEVATION       0\n",
      "DATE            0\n",
      "PRCP           37\n",
      "TAVG            0\n",
      "TMAX          959\n",
      "TMIN         1646\n",
      "dtype: int64\n",
      "\n",
      "Number of Duplicate Rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Load the  dataset\n",
    "df = pd.read_csv('D:\\DESKTOP\\DE CW\\External_Data.csv')\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)\n",
    "\n",
    "# Check for duplicates\n",
    "duplicate_rows = df.duplicated().sum()\n",
    "print(\"\\nNumber of Duplicate Rows:\", duplicate_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIssing values handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv('D:\\DESKTOP\\DE CW\\External_Data.csv')\n",
    "\n",
    "# Group the dataset by the \"NAME\" column\n",
    "grouped = df.groupby('NAME')\n",
    "\n",
    "# Iterate over the groups and save each subset\n",
    "for name, group in grouped:\n",
    "    group.to_csv(f'{name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values in Dataset A:\n",
      " STATION        0\n",
      "NAME           0\n",
      "LATITUDE       0\n",
      "LONGITUDE      0\n",
      "ELEVATION      0\n",
      "DATE           0\n",
      "PRCP           9\n",
      "TAVG           0\n",
      "TMAX         209\n",
      "TMIN         317\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Dataset B:\n",
      " STATION        0\n",
      "NAME           0\n",
      "LATITUDE       0\n",
      "LONGITUDE      0\n",
      "ELEVATION      0\n",
      "DATE           0\n",
      "PRCP           3\n",
      "TAVG           0\n",
      "TMAX         160\n",
      "TMIN         265\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Dataset C:\n",
      " STATION        0\n",
      "NAME           0\n",
      "LATITUDE       0\n",
      "LONGITUDE      0\n",
      "ELEVATION      0\n",
      "DATE           0\n",
      "PRCP           5\n",
      "TAVG           0\n",
      "TMAX         214\n",
      "TMIN         344\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load dataset A\n",
    "df_A = pd.read_csv('D:\\DESKTOP\\DE CW\\COLOMBO, CE.csv')\n",
    "\n",
    "# Load dataset B\n",
    "df_B = pd.read_csv('D:\\DESKTOP\\DE CW\\KURUNEGALA, CE.csv')\n",
    "\n",
    "# Load dataset C\n",
    "df_C = pd.read_csv('NUWARA ELIYA, CE.csv')\n",
    "\n",
    "# Check for missing values in dataset A\n",
    "missing_values_A = df_A.isnull().sum()\n",
    "print(\"Missing Values in Dataset A:\\n\", missing_values_A)\n",
    "\n",
    "# Check for missing values in dataset B\n",
    "missing_values_B = df_B.isnull().sum()\n",
    "print(\"\\nMissing Values in Dataset B:\\n\", missing_values_B)\n",
    "\n",
    "# Check for missing values in dataset C\n",
    "missing_values_C = df_C.isnull().sum()\n",
    "print(\"\\nMissing Values in Dataset C:\\n\", missing_values_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COLOMBO, CE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values filling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dee\\AppData\\Local\\Temp\\ipykernel_20868\\3196407785.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data[\"PRCP\"] = model_PRCP.predict(X_missing)\n",
      "C:\\Users\\Dee\\AppData\\Local\\Temp\\ipykernel_20868\\3196407785.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data[\"TMAX\"] = model_TMAX.predict(X_missing)\n",
      "C:\\Users\\Dee\\AppData\\Local\\Temp\\ipykernel_20868\\3196407785.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data[\"TMIN\"] = model_TMIN.predict(X_missing)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"D:\\DESKTOP\\DE CW\\COLOMBO, CE.csv\")\n",
    "\n",
    "# Drop the \"STATION\" column\n",
    "data.drop(\"STATION\", axis=1, inplace=True)\n",
    "\n",
    "# Encode text values\n",
    "label_encoders = {}\n",
    "for column in [\"NAME\", \"DATE\"]:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "# Split data into complete and missing parts\n",
    "complete_data = data.dropna(subset=[\"NAME\", \"LATITUDE\", \"LONGITUDE\", \"ELEVATION\", \"DATE\", \"TAVG\"])\n",
    "missing_data = data[data[\"PRCP\"].isnull() | data[\"TMAX\"].isnull() | data[\"TMIN\"].isnull()]\n",
    "\n",
    "# Remove rows with missing target values\n",
    "complete_data.dropna(subset=[\"PRCP\", \"TMAX\", \"TMIN\"], inplace=True)\n",
    "\n",
    "# Define features and target variables\n",
    "features = [\"NAME\", \"LATITUDE\", \"LONGITUDE\", \"ELEVATION\", \"DATE\", \"TAVG\"]\n",
    "target_PRCP = \"PRCP\"\n",
    "target_TMAX = \"TMAX\"\n",
    "target_TMIN = \"TMIN\"\n",
    "\n",
    "# Select features and target for complete data\n",
    "X_train = complete_data[features]\n",
    "y_train_PRCP = complete_data[target_PRCP]\n",
    "y_train_TMAX = complete_data[target_TMAX]\n",
    "y_train_TMIN = complete_data[target_TMIN]\n",
    "\n",
    "# Train model for PRCP\n",
    "model_PRCP = LinearRegression()\n",
    "model_PRCP.fit(X_train, y_train_PRCP)\n",
    "\n",
    "# Train model for TMAX\n",
    "model_TMAX = LinearRegression()\n",
    "model_TMAX.fit(X_train, y_train_TMAX)\n",
    "\n",
    "# Train model for TMIN\n",
    "model_TMIN = LinearRegression()\n",
    "model_TMIN.fit(X_train, y_train_TMIN)\n",
    "\n",
    "# Predict missing values\n",
    "X_missing = missing_data[features]\n",
    "missing_data[\"PRCP\"] = model_PRCP.predict(X_missing)\n",
    "missing_data[\"TMAX\"] = model_TMAX.predict(X_missing)\n",
    "missing_data[\"TMIN\"] = model_TMIN.predict(X_missing)\n",
    "\n",
    "# Merge imputed data back into original dataset\n",
    "imputed_data = pd.concat([complete_data, missing_data])\n",
    "\n",
    "# Decode text values\n",
    "for column in [\"NAME\", \"DATE\"]:\n",
    "    imputed_data[column] = label_encoders[column].inverse_transform(imputed_data[column])\n",
    "\n",
    "# Save or use imputed_data as needed\n",
    "imputed_data.to_csv(\"D:/DESKTOP/DE CW/COLOMBO_CE_FIX.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KURUNEGALA, CE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values filling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dee\\AppData\\Local\\Temp\\ipykernel_20868\\3482462062.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data[\"PRCP\"] = model_PRCP.predict(X_missing)\n",
      "C:\\Users\\Dee\\AppData\\Local\\Temp\\ipykernel_20868\\3482462062.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data[\"TMAX\"] = model_TMAX.predict(X_missing)\n",
      "C:\\Users\\Dee\\AppData\\Local\\Temp\\ipykernel_20868\\3482462062.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data[\"TMIN\"] = model_TMIN.predict(X_missing)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"D:\\DESKTOP\\DE CW\\KURUNEGALA, CE.csv\")\n",
    "\n",
    "# Drop the \"STATION\" column\n",
    "data.drop(\"STATION\", axis=1, inplace=True)\n",
    "\n",
    "# Encode text values\n",
    "label_encoders = {}\n",
    "for column in [\"NAME\", \"DATE\"]:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "# Split data into complete and missing parts\n",
    "complete_data = data.dropna(subset=[\"NAME\", \"LATITUDE\", \"LONGITUDE\", \"ELEVATION\", \"DATE\", \"TAVG\"])\n",
    "missing_data = data[data[\"PRCP\"].isnull() | data[\"TMAX\"].isnull() | data[\"TMIN\"].isnull()]\n",
    "\n",
    "# Remove rows with missing target values\n",
    "complete_data.dropna(subset=[\"PRCP\", \"TMAX\", \"TMIN\"], inplace=True)\n",
    "\n",
    "# Define features and target variables\n",
    "features = [\"NAME\", \"LATITUDE\", \"LONGITUDE\", \"ELEVATION\", \"DATE\", \"TAVG\"]\n",
    "target_PRCP = \"PRCP\"\n",
    "target_TMAX = \"TMAX\"\n",
    "target_TMIN = \"TMIN\"\n",
    "\n",
    "# Select features and target for complete data\n",
    "X_train = complete_data[features]\n",
    "y_train_PRCP = complete_data[target_PRCP]\n",
    "y_train_TMAX = complete_data[target_TMAX]\n",
    "y_train_TMIN = complete_data[target_TMIN]\n",
    "\n",
    "# Train model for PRCP\n",
    "model_PRCP = LinearRegression()\n",
    "model_PRCP.fit(X_train, y_train_PRCP)\n",
    "\n",
    "# Train model for TMAX\n",
    "model_TMAX = LinearRegression()\n",
    "model_TMAX.fit(X_train, y_train_TMAX)\n",
    "\n",
    "# Train model for TMIN\n",
    "model_TMIN = LinearRegression()\n",
    "model_TMIN.fit(X_train, y_train_TMIN)\n",
    "\n",
    "# Predict missing values\n",
    "X_missing = missing_data[features]\n",
    "missing_data[\"PRCP\"] = model_PRCP.predict(X_missing)\n",
    "missing_data[\"TMAX\"] = model_TMAX.predict(X_missing)\n",
    "missing_data[\"TMIN\"] = model_TMIN.predict(X_missing)\n",
    "\n",
    "# Merge imputed data back into original dataset\n",
    "imputed_data = pd.concat([complete_data, missing_data])\n",
    "\n",
    "# Decode text values\n",
    "for column in [\"NAME\", \"DATE\"]:\n",
    "    imputed_data[column] = label_encoders[column].inverse_transform(imputed_data[column])\n",
    "\n",
    "# Save or use imputed_data as needed\n",
    "imputed_data.to_csv(\"D:/DESKTOP/DE CW/KURUNEGALA_CE_FIX.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUWARA ELIYA, CE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values filling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dee\\AppData\\Local\\Temp\\ipykernel_20868\\916796597.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data[\"PRCP\"] = model_PRCP.predict(X_missing)\n",
      "C:\\Users\\Dee\\AppData\\Local\\Temp\\ipykernel_20868\\916796597.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data[\"TMAX\"] = model_TMAX.predict(X_missing)\n",
      "C:\\Users\\Dee\\AppData\\Local\\Temp\\ipykernel_20868\\916796597.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data[\"TMIN\"] = model_TMIN.predict(X_missing)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"NUWARA ELIYA, CE.csv\")\n",
    "\n",
    "# Drop the \"STATION\" column\n",
    "data.drop(\"STATION\", axis=1, inplace=True)\n",
    "\n",
    "# Encode text values\n",
    "label_encoders = {}\n",
    "for column in [\"NAME\", \"DATE\"]:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "# Split data into complete and missing parts\n",
    "complete_data = data.dropna(subset=[\"NAME\", \"LATITUDE\", \"LONGITUDE\", \"ELEVATION\", \"DATE\", \"TAVG\"])\n",
    "missing_data = data[data[\"PRCP\"].isnull() | data[\"TMAX\"].isnull() | data[\"TMIN\"].isnull()]\n",
    "\n",
    "# Remove rows with missing target values\n",
    "complete_data.dropna(subset=[\"PRCP\", \"TMAX\", \"TMIN\"], inplace=True)\n",
    "\n",
    "# Define features and target variables\n",
    "features = [\"NAME\", \"LATITUDE\", \"LONGITUDE\", \"ELEVATION\", \"DATE\", \"TAVG\"]\n",
    "target_PRCP = \"PRCP\"\n",
    "target_TMAX = \"TMAX\"\n",
    "target_TMIN = \"TMIN\"\n",
    "\n",
    "# Select features and target for complete data\n",
    "X_train = complete_data[features]\n",
    "y_train_PRCP = complete_data[target_PRCP]\n",
    "y_train_TMAX = complete_data[target_TMAX]\n",
    "y_train_TMIN = complete_data[target_TMIN]\n",
    "\n",
    "# Train model for PRCP\n",
    "model_PRCP = LinearRegression()\n",
    "model_PRCP.fit(X_train, y_train_PRCP)\n",
    "\n",
    "# Train model for TMAX\n",
    "model_TMAX = LinearRegression()\n",
    "model_TMAX.fit(X_train, y_train_TMAX)\n",
    "\n",
    "# Train model for TMIN\n",
    "model_TMIN = LinearRegression()\n",
    "model_TMIN.fit(X_train, y_train_TMIN)\n",
    "\n",
    "# Predict missing values\n",
    "X_missing = missing_data[features]\n",
    "missing_data[\"PRCP\"] = model_PRCP.predict(X_missing)\n",
    "missing_data[\"TMAX\"] = model_TMAX.predict(X_missing)\n",
    "missing_data[\"TMIN\"] = model_TMIN.predict(X_missing)\n",
    "\n",
    "# Merge imputed data back into original dataset\n",
    "imputed_data = pd.concat([complete_data, missing_data])\n",
    "\n",
    "# Decode text values\n",
    "for column in [\"NAME\", \"DATE\"]:\n",
    "    imputed_data[column] = label_encoders[column].inverse_transform(imputed_data[column])\n",
    "\n",
    "# Save or use imputed_data as needed\n",
    "imputed_data.to_csv(\"D:/DESKTOP/DE CW/_NUWARA_ELIYA_CE_FIX.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make New data set  using filled missing values  data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets A, B, and C\n",
    "data_A = pd.read_csv(\"D:/DESKTOP/DE CW/COLOMBO_CE_FIX.csv\")\n",
    "data_B = pd.read_csv(\"D:/DESKTOP/DE CW/KURUNEGALA_CE_FIX.csv\")\n",
    "data_C = pd.read_csv(\"D:/DESKTOP/DE CW/_NUWARA_ELIYA_CE_FIX.csv\")\n",
    "\n",
    "# Concatenate datasets A, B, and C along the rows\n",
    "combined_data = pd.concat([data_A, data_B, data_C], ignore_index=True)\n",
    "\n",
    "# Save the combined dataset to a new CSV file\n",
    "combined_data.to_csv(\"Extra_factors_Final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: NAME\n",
      "['COLOMBO, CE' 'KURUNEGALA, CE' 'NUWARA ELIYA, CE']\n",
      "\n",
      "Column: LATITUDE\n",
      "[6.9   7.467 6.967]\n",
      "\n",
      "Column: LONGITUDE\n",
      "[79.867 80.367 80.767]\n",
      "\n",
      "Column: ELEVATION\n",
      "[   7.  116. 1880.]\n",
      "\n",
      "Column: DATE\n",
      "['2019-01-01' '2019-01-03' '2019-01-04' ... '2022-09-20' '2022-01-12'\n",
      " '2022-03-02']\n",
      "\n",
      "Column: PRCP\n",
      "[0.         0.52       0.02       ... 0.27606336 0.24885447 0.27650289]\n",
      "\n",
      "Column: TAVG\n",
      "[81 82 83 79 78 80 84 85 87 86 76 77 75 88 89 90 91 92 72 69 61 59 62 60\n",
      " 56 53 57 58 63 64 65 66 67 55 52 54 68 51]\n",
      "\n",
      "Column: TMAX\n",
      "[89.         90.         91.         ... 67.1123443  68.24911482\n",
      " 67.10795642]\n",
      "\n",
      "Column: TMIN\n",
      "[74.         72.         73.         ... 54.6439349  55.35647934\n",
      " 54.65645071]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"Extra_factors_Final.csv\")\n",
    "\n",
    "# Display column names with their values\n",
    "for column in data.columns:\n",
    "    print(f\"Column: {column}\")\n",
    "    print(data[column].unique())\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
